{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Descripition \n",
    "\n",
    "In 2012, URL shortening service Bitly partnered with the US government website USA.gov to provide a feed of anonymous data gathered from users who shorten links ending with .gov or .mil.\n",
    "\n",
    "The text file comes in JSON format and here are some keys and their description. They are only the most important ones for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|key| description |\n",
    "|---|-----------|\n",
    "| a|Denotes information about the web browser and operating system|\n",
    "| tz | time zone |\n",
    "| r | URL the user come from |\n",
    "| u | URL where the user headed to |\n",
    "| t | Timestamp when the user start using the website in UNIX format |\n",
    "| hc | Timestamp when user exit the website in UNIX format |\n",
    "| cy | City from which the request intiated |\n",
    "| ll | Longitude and Latitude |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell, I tried to provide some helper code for better understanding and clearer vision\n",
    "\n",
    "-**HINT**- Those lines of code may be not helping at all with your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.78 Safari/535.11',\n",
       " 'c': 'US',\n",
       " 'nk': 1,\n",
       " 'tz': 'America/New_York',\n",
       " 'gr': 'MA',\n",
       " 'g': 'A6qOVH',\n",
       " 'h': 'wfLQtf',\n",
       " 'l': 'orofrog',\n",
       " 'al': 'en-US,en;q=0.8',\n",
       " 'hh': '1.usa.gov',\n",
       " 'r': 'http://www.facebook.com/l/7AQEFzjSi/1.usa.gov/wfLQtf',\n",
       " 'u': 'http://www.ncbi.nlm.nih.gov/pubmed/22415991',\n",
       " 't': 1331923247,\n",
       " 'hc': 1331822918,\n",
       " 'cy': 'Danvers',\n",
       " 'll': [42.576698, -70.954903]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will try to retrieve one instance of the file in a list of dictionaries\n",
    "import json\n",
    "records = [json.loads(line) for line in open('usa.gov_click_data.json')]\n",
    "# Print the first occurance\n",
    "records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a script can transform the JSON files to a DataFrame and commit each file to a sparete CSV file in the target directory and consider the following:\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All CSV files must have the following columns\n",
    "- web_browser\n",
    "        The web browser that has requested the service\n",
    "- operating_sys\n",
    "        operating system that intiated this request\n",
    "- from_url\n",
    "\n",
    "        The main URL the user came from\n",
    "\n",
    "    **note**:\n",
    "\n",
    "    If the retrived URL was in a long format `http://www.facebook.com/l/7AQEFzjSi/1.usa.gov/wfLQtf`\n",
    "\n",
    "     make it appear in the file in a short format like this `www.facebook.com`\n",
    "     \n",
    "    \n",
    "- to_url\n",
    "\n",
    "       The same applied like `to_url`\n",
    "   \n",
    "- city\n",
    "\n",
    "        The city from which the the request was sent\n",
    "    \n",
    "- longitude\n",
    "\n",
    "        The longitude where the request was sent\n",
    "- latitude\n",
    "\n",
    "        The latitude where the request was sent\n",
    "\n",
    "- time_zone\n",
    "        \n",
    "        The time zone that the city follow\n",
    "        \n",
    "- time_in\n",
    "\n",
    "        Time when the request started\n",
    "- time_out\n",
    "        \n",
    "        Time when the request is ended\n",
    "        \n",
    "        \n",
    "**NOTE** :\n",
    "\n",
    "Because that some instances of the file are incomplete, you may encouter some NaN values in your transforamtion. Make sure that the final dataframes have no NaNs at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c2b27b5500a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# place the json records into a pandas dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# place the json records into a pandas dataframe\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The records with '_heartbeat_' were not part of the data so they were removed\n",
    "df.drop(df[df['_heartbeat_'].notnull()].index, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unnecessary columns and reset the index\n",
    "df.drop(columns = ['_heartbeat_', 'al', 'c', 'g', 'gr', 'h', 'hh', 'kw', 'l', 'nk'], inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#print an example of the data\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Web Browser & Operating System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the values in the 'a' columns to infer how to extract the browser name and OS\n",
    "df['a'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract the browser as the first word in the entry\n",
    "\n",
    "def get_browser(text):\n",
    "    browser = ''\n",
    "    for alpha in text:\n",
    "        if alpha.isalpha() is False:\n",
    "            break\n",
    "        browser = browser + alpha\n",
    "    return browser\n",
    "\n",
    "#function to extract the OS as the first attribute between brackets.\n",
    "#If there are no brackets, then the OS is not mentioned in the entry.\n",
    "def get_OS(text):\n",
    "    OS = ''\n",
    "    if '(' in text:\n",
    "        for alpha in text[text.index('(')+1:]:\n",
    "            if alpha.isalpha() is False:\n",
    "                break\n",
    "            OS = OS + alpha\n",
    "        return OS\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply functions to get browser and OS in new columns\n",
    "df['web_browser'] = df['a'].apply(get_browser)\n",
    "df['operating_sys'] = df['a'].apply(get_OS)\n",
    "\n",
    "#Drop the old column\n",
    "df.drop(columns = 'a', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print output from web_browser\n",
    "df['web_browser'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print output values for the OS\n",
    "df['operating_sys'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for easier handling\n",
    "df.rename(columns = {'r' : 'from_url', 'u' : 'to_url'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to extract the general url from the data\n",
    "def get_url(text):\n",
    "    if text == 'direct':\n",
    "        return text\n",
    "    \n",
    "    #url starts after //\n",
    "    text = text[text.index('/')+2:]\n",
    "    \n",
    "    #url ends with the end of the line or another /\n",
    "    clean_url = text[:text.index('/')] if '/' in text else text \n",
    "    \n",
    "    return clean_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply function on the url column to clean them\n",
    "df['from_url'] = df['from_url'].apply(get_url)\n",
    "df['to_url'] = df['to_url'].apply(get_url)\n",
    "\n",
    "#print a sample to see the output\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column ll has both in a list where index 0 is the latitude and 1 is the longitude\n",
    "\n",
    "#Extract the longitude\n",
    "def get_long(text):\n",
    "    if text is np.NaN:\n",
    "        # If the long and lat are not provided, return NaN\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return text[1]\n",
    "\n",
    "#Extra the latitude\n",
    "def get_lat(text):\n",
    "    if text is np.NaN:\n",
    "        # If the long and lat are not provided, return NaN\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Place longitude in new column\n",
    "df['longitude'] = df['ll'].apply(get_long)\n",
    "\n",
    "#replace column ll to have only the latitude and rename\n",
    "df['ll'] = df['ll'].apply(get_lat)\n",
    "df.rename(columns = {'ll' : 'latitude'}, inplace = True)\n",
    "\n",
    "#print a sample to see the output\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Date and Time from the Unix Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change time from UNIX format\n",
    "df['hc'] = pd.to_datetime(df['hc'], unit='s').dt.tz_localize('GMT')\n",
    "df['t'] = pd.to_datetime(df['t'], unit='s').dt.tz_localize('GMT')\n",
    "\n",
    "#Note that the dates have been localized to the Greenwich timezone for consistency ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns as per the request\n",
    "df.rename(columns = {'t' : 'time_in', 'hc' : 'time_out'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up final columns and renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'cy' : 'city', 'tz' : 'timezone'}, inplace = True)\n",
    "\n",
    "#Clean Time zone column to make it readable\n",
    "df['timezone'] = df['timezone'].str.replace('/', ', ')\n",
    "df['timezone'] = df['timezone'].str.replace('_', ' ')\n",
    "\n",
    "#reorder columns for better readability\n",
    "df = df[['web_browser', 'operating_sys',\n",
    "         'from_url', 'to_url',\n",
    "         'city', 'longitude', 'latitude',\n",
    "         'timezone', 'time_in', 'time_out']]\n",
    "\n",
    "#print the final cleaned and ordered dataframe\n",
    "df.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Basic_ML",
   "language": "python",
   "name": "basic_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
